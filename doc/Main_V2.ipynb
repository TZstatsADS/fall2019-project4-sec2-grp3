{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Main_V2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwzhXCQV2ZQB",
        "colab_type": "text"
      },
      "source": [
        "# Group 3 Project 4 - Collaborative Filtering (A1 vs A2 given P3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x15KB_32ZQD",
        "colab_type": "text"
      },
      "source": [
        "## Kanyan Chen, Dingyi Fang, Yuhan Gong, Feichi Gu, Haoyu Zhang"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia2048pv2ZQE",
        "colab_type": "text"
      },
      "source": [
        "## 11/21/2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sGh82Al2ZQE",
        "colab_type": "text"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qli4KXm52ZQF",
        "colab_type": "text"
      },
      "source": [
        "These days we are constantly being recommended from various sources, such as suitable movies and popular music. **Collaborative Filtering** builds recommender system by analyzing relationships between users and interdependencies among items. One of methods to achieve Collaborative Filtering is **Latent Factor Models**.\n",
        "\n",
        "Latent Factor Models characterizes both items and users on some factors inferred from the ratings patterns. This process is called **Matrix Factorization**. The major work of this project is to implement, evaluate and compare two matrix factorization techniques: **Stochastic Gradient Descent** (A1) and **Gradient Descent with Probabilistic Assumptions** (A2) based on RMSE and running time. To improve accuracy of factorization, we are assigned to use **kernel ridge regression** (P3) to postprocess previous SVD results. In this file, we will present our data preprocessing, algorithm implementation, evaluation results as well as some further discussions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJDGWH8k2ZQG",
        "colab_type": "text"
      },
      "source": [
        "## Step 0:  Load packages and process data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E-l4gB42ZQH",
        "colab_type": "text"
      },
      "source": [
        "### 0.1 load packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxhuzo7-2ZQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import timeit\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.kernel_ridge import KernelRidge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypYe3jlV2ZQJ",
        "colab_type": "text"
      },
      "source": [
        "### 0.2 load and process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyGsvacN2ZQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## load rating data\n",
        "\n",
        "from google.colab import files\n",
        "import io\n",
        "uploaded = files.upload()\n",
        "Rate = pd.read_csv(io.BytesIO(uploaded['ratings.csv']))\n",
        "\n",
        "\n",
        "#Rate = pd.read_csv(\"C:\\\\Users\\\\think\\\\Desktop\\\\project4\\\\ratings.csv\")\n",
        "\n",
        "## create dictionaries to relabel userId and movieId for future convenience\n",
        "list_user = Rate.userId.unique()\n",
        "dict_user = {}\n",
        "for i in range(len(list_user)):\n",
        "    dict_user[list_user[i]] = i\n",
        "    \n",
        "list_movie = Rate.movieId.unique()    \n",
        "dict_movie = {}\n",
        "for i in range(len(list_movie)):\n",
        "    dict_movie[list_movie[i]]=i\n",
        "\n",
        "## relabel original dataset with above ordinal number\n",
        "for i in range(len(Rate)):\n",
        "    Rate[\"userId\"][i] = dict_user[Rate[\"userId\"][i]]\n",
        "    Rate[\"movieId\"][i] = dict_movie[Rate[\"movieId\"][i]]\n",
        "\n",
        "## Train, Test split\n",
        "# we split dataset by 9:1 rather than common 8:2 or 7:3 because of cold start problem\n",
        "# If our training set is too sparse, then we cannot recommend anything if new movieId exist in testing set \n",
        "Train, Test = train_test_split(Rate, test_size = 0.1)\n",
        "\n",
        "Train_user = list(Train[\"userId\"])\n",
        "Train_movie = list(Train[\"movieId\"])\n",
        "Train_rate = list(Train[\"rating\"])\n",
        "\n",
        "Test_user = list(Test[\"userId\"])\n",
        "Test_movie = list(Test[\"movieId\"])\n",
        "Test_rate = list(Test[\"rating\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWPgD8sI2ZQO",
        "colab_type": "text"
      },
      "source": [
        "## Step 1:  implementing  A1 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9MAMjCW2ZQP",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Introduction about Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H8YhyAj2ZQP",
        "colab_type": "text"
      },
      "source": [
        "As mentioned in Paper 1, the concept of matrix factorization can be written mathematically as $\\hat{\\mathbf{R}}=\\mathbf{Q}^\\intercal \\mathbf{P}$ where latent movie feature vector $Q$ and latent user feature vector $P$ are (k,m) and (k,n) matrices respectively.\n",
        "Then we can create following objective function that we want to minimize with respect to $Q$ and $P:$ $\\sum (r_{ui}-q_{i}^\\intercal {p_{u}})^{2}+ \\lambda ({\\| q_{i}\\|}^2+{\\| p_{u}\\|}^2)$. The term on the left is prediction error term. The term on the right is the regularization term. This is added since we do not want our decomposed matrix $Q$ and $P$ to overfit the observed data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4mb_TYN2ZQQ",
        "colab_type": "text"
      },
      "source": [
        "One obvious method to find matrix $Q$ and $P$  is the ** Stochastic Gradient Descent** method. Since we have the loss function defined above, we can take the partial derivative respect to $q$ and $p$ to optimize existing values. The updating rule look like as below: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF6bTgne2ZQR",
        "colab_type": "text"
      },
      "source": [
        "$q_{i} \\leftarrow q_{i} + \\gamma \\cdot(e_{ui} \\cdot p_{u}-\\lambda  \\cdot q_{i})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a81YxBS2ZQS",
        "colab_type": "text"
      },
      "source": [
        "$p_{u} \\leftarrow p_{u} + \\gamma \\cdot(e_{ui} \\cdot q_{i}-\\lambda  \\cdot p_{u})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3EcuPQh2ZQS",
        "colab_type": "text"
      },
      "source": [
        "In addition, to compare different algorithms and tune paramters, we mainly use measure Root Mean Square Error, the formula is as below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqlNDuye2ZQT",
        "colab_type": "text"
      },
      "source": [
        "$RMSE = \\sqrt{\\cfrac{1}{n} \\cdot \\sum({r_{ui}-\\hat{r_{ui}})^2}} $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fQrK86h2ZQT",
        "colab_type": "text"
      },
      "source": [
        "We create Python scripts to implement this algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxotqPgo2ZQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## for A1, we use cross validation shown in 2.2 to find the optimal parameters: \n",
        "## factor = 15, lambda = 0.1, lr = 0.01  \n",
        "\n",
        "def A1(Factor=20, Lambda=0.05, epochs=200, lr=0.01):\n",
        "    ## set initial values for P & Q; history will show updating RMSE\n",
        "    mu = (sum(Train_rate)/Factor/len(Train_rate))**.5\n",
        "    P = np.random.normal(mu, .05, (len(list_user),Factor))\n",
        "    Q = np.random.normal(mu, .05, (len(list_movie),Factor))\n",
        "    history = np.zeros((epochs,2))\n",
        "    last_change = 0\n",
        "\n",
        "    for iteration in range(epochs):\n",
        "        for i in range(len(Train)):\n",
        "            \n",
        "            ## find label or the ordinal for the user and movie\n",
        "            user = Train_user[i] \n",
        "            movie = Train_movie[i] \n",
        "            error = Train_rate[i]-np.dot(Q[movie],P[user])\n",
        "            temp = Q[movie]\n",
        "            \n",
        "            ## gradient descent\n",
        "            Q[movie] = Q[movie] + lr*(error*P[user]-Lambda*Q[movie])\n",
        "            P[user] = P[user] + lr*(error*temp-Lambda*P[user])\n",
        "            \n",
        "        ## calculate training and testing rmse after each epoch\n",
        "        history[iteration,0] = (sum([(Train_rate[i]-np.dot(Q[Train_movie[i]],P[Train_user[i]]))**2 for i in range(len(Train))])/len(Train))**.5\n",
        "        history[iteration,1] = (sum([(Test_rate[i]-np.dot(Q[Test_movie[i]],P[Test_user[i]]))**2 for i in range(len(Test))])/len(Test))**.5\n",
        "        print(iteration,history[iteration,:])\n",
        "        \n",
        "        ## automatically change learning rate to avoid diverging\n",
        "        if iteration-last_change>=30 and lr>0.0002:\n",
        "            lr = lr * 0.4\n",
        "            last_change = iteration\n",
        "            print(\"learning rate change to \",lr)\n",
        "    \n",
        "    return P,Q,history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33rUt0cU2ZQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## show RMSE history for training and testing set based on A1; and calculate running time\n",
        "\n",
        "start1 = timeit.default_timer()\n",
        "result1 = A1(epochs=200)\n",
        "stop1 = timeit.default_timer()\n",
        "\n",
        "print('Running Time for A1: ', stop1 - start1, 's')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm1KRCo62ZQY",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhqyMU1t2ZQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from itertools import product\n",
        "import multiprocessing\n",
        "    \n",
        "## Train Test split\n",
        "K = 5\n",
        "Train_list = []\n",
        "kf = KFold(n_splits = K,shuffle = True)\n",
        "for Train_index in kf.split(Rate):\n",
        "    Train_list = Train_list + [Rate.iloc[Train_index]]\n",
        "    \n",
        "def Df_to_list(Train,Test):\n",
        "    Train_user = list(Train[\"userId\"])\n",
        "    Train_movie = list(Train[\"movieId\"])\n",
        "    Train_rate = list(Train[\"rating\"])\n",
        "    Test_user = list(Test[\"userId\"])\n",
        "    Test_movie = list(Test[\"movieId\"])\n",
        "    Test_rate = list(Test[\"rating\"])\n",
        "    return Train_user,Train_movie,Train_rate,Test_user,Test_movie,Test_rate\n",
        "\n",
        "\n",
        "def SGD_CV(pairs):\n",
        "    factor = pairs[0]\n",
        "    lambda_A1 = pairs[1]\n",
        "    epochs = pairs[2]\n",
        "    best_rmse = []\n",
        "    for k in range(K):\n",
        "        lr = pairs[3]\n",
        "        P = np.random.normal(0, .1, (len(list_user),factor))\n",
        "        Q = np.random.normal(0, .1, (len(list_movie),factor))\n",
        "        Train_user, Train_movie, Train_rate, Validation_user, Validation_movie, Validation_rate = Df_to_list(Train_list[k],Validation_list[k])\n",
        "        history = np.zeros((epochs,2))\n",
        "        for _ in range(epochs):\n",
        "            for i in range(len(Train_user)):\n",
        "                user = Train_user[i]\n",
        "                movie = Train_movie[i]\n",
        "                error = Train_rate[i]-np.dot(Q[movie],P[user])\n",
        "                temp = Q[movie]\n",
        "                Q[movie] = Q[movie] + lr*(error*P[user]-lambda_A1*Q[movie])\n",
        "                P[user] = P[user] + lr*(error*temp-lambda_A1*P[user])\n",
        "                # calculate training and testing rmse after each epoch\n",
        "            #history[_,0] = sum([(Train_rate[i]-np.dot(Q[Train_movie[i]],P[Train_user[i]]))**2 for i in range(len(Train_user))])/len(Train_user)\n",
        "            #history[_,1] = sum([(Validation_rate[i]-np.dot(Q[Validation_movie[i]],P[Validation_user[i]]))**2 for i in range(len(Validation_user))])/len(Validation_user)\n",
        "            #print(_,history[_,0],history[_,1])\n",
        "            if _%30==0 and _>0 and lr>0.0001:\n",
        "                lr = lr * 0.4\n",
        "        best_rmse.append((sum([(Validation_rate[i]-np.dot(Q[Validation_movie[i]],P[Validation_user[i]]))**2 for i in range(len(Validation_user))])/len(Validation_user))**.5)\n",
        "    return best_rmse,factor,lambda_A1,epochs,lr\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    P = [[8,10,12,15,20],[0.05,0.1,0.15,0.2],[500],[0.01]] # Factor, lambda, epochs(should be 300, 20 is for testing only),learning rate \n",
        "    pairs = product(*P)\n",
        "    pool = multiprocessing.Pool() # change the process amount based on your own CPU, default is using all Threads\n",
        "    result = pool.map(SGD_CV, pairs)\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "    with open('A1.txt', 'w') as file:\n",
        "        for i in result:\n",
        "            file.writelines(str(sum(i[0])/K))\n",
        "            file.writelines([str(t)+',' for t in i[1:]]+[\"\\n\"])\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EM3Kb9u2ZQb",
        "colab_type": "text"
      },
      "source": [
        "## Step 2:   Implementing  A2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK59yU_12ZQb",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Introduction about Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2VHAhNf2ZQc",
        "colab_type": "text"
      },
      "source": [
        "In brief, Probabilistic Matrix Factorization is a simple probabilistic model with Gaussian observation\n",
        "noise. Similar to A1, as indicated in Paper 2, we should minimize the sum-of-squared-errors objective function with respect to $Q$ and $P :$ $$\\frac{1}{2} \\sum_{i=1}^{N} \\sum_{u=1}^{M} I_{ui}(r_{ui}-q_{i}^\\intercal {p_{u}})^2 + \\frac{\\lambda_{q}}{2} \\sum_{i=1}^{N}{\\| q_{i}\\|}^2 + \\frac{\\lambda_{p}}{2}\\sum_{u=1}^{M}{\\| p_{u}\\|}^2$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8rM4M0P2ZQd",
        "colab_type": "text"
      },
      "source": [
        "$I_{ui}$ is the indicator function that is equal to 1 if user $u$ rated movie $i$ and equal to 0 otherwise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0HXXBTF2ZQd",
        "colab_type": "text"
      },
      "source": [
        "We also use gradient descent to find local minimum of the above objective function. Scripts are as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmI5w4dk2ZQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## for A2, we use cross validation shown in 3.2 to find the optimal parameters: \n",
        "## factor = 5, Lambda_P = 0.1, Lambda_Q = 0.1, lr = 0.0001  \n",
        "\n",
        "def A2(Factor=5, Lambda_P=0.1, Lambda_Q=0.1, epochs=500, lr=0.0001):\n",
        "    mu = (sum(Train_rate)/Factor/len(Train_rate))**.5\n",
        "    P = np.random.normal(mu, .05, (len(list_user),Factor))\n",
        "    Q = np.random.normal(mu, .05, (len(list_movie),Factor))\n",
        "    history = np.zeros((epochs,2))\n",
        "    for iteration in range(epochs):\n",
        "        Gradient_P = np.zeros((len(list_user),Factor))\n",
        "        Gradient_Q = np.zeros((len(list_movie),Factor))\n",
        "        \n",
        "        for i in range(len(Train)):\n",
        "            user = Train_user[i]\n",
        "            movie = Train_movie[i]\n",
        "            error = Train_rate[i]-np.dot(Q[movie],P[user])\n",
        "            Gradient_P[user] += error * Q[movie] \n",
        "            Gradient_Q[movie] += error * P[user]\n",
        "        for i in range(len(list_user)):\n",
        "            Gradient_P[i] -= Lambda_P * P[i]\n",
        "        for i in range(len(list_movie)):\n",
        "            Gradient_Q[i] -= Lambda_Q * Q[i]\n",
        "        P = P + lr*Gradient_P\n",
        "        Q = Q + lr*Gradient_Q\n",
        "        \n",
        "        # calculate training and testing rmse after each epoch\n",
        "        history[iteration,0] = (sum([(Train_rate[i]-np.dot(Q[Train_movie[i]],P[Train_user[i]]))**2 for i in range(len(Train))])/len(Train))**.5\n",
        "        history[iteration,1] = (sum([(Test_rate[i]-np.dot(Q[Test_movie[i]],P[Test_user[i]]))**2 for i in range(len(Test))])/len(Test))**.5\n",
        "        print(iteration,history[iteration])\n",
        "    return P,Q,history\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxWI2BhY2ZQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## show RMSE history for training and testing set based on A2; calculate running time\n",
        "\n",
        "start2 = timeit.default_timer()\n",
        "result2 = A2()\n",
        "stop2 = timeit.default_timer()\n",
        "\n",
        "print('Running Time for A1: ', stop2 - start2, 's')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08gpimAt2ZQi",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og93dkLw2ZQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "def GD_CV(pairs):\n",
        "    factor = pairs[0]\n",
        "    Lambda_P = pairs[1]\n",
        "    Lambda_Q = pairs[2]\n",
        "    epochs = pairs[3]\n",
        "    lr = pairs[4]\n",
        "    best_rmse = []\n",
        "    for k in range(K):\n",
        "        lr = pairs[4]\n",
        "        P = np.random.normal(0, .1, (len(list_user),factor))\n",
        "        Q = np.random.normal(0, .1, (len(list_movie),factor))\n",
        "        Train_user, Train_movie, Train_rate, Validation_user, Validation_movie, Validation_rate = Df_to_list(Train_list[k],Validation_list[k])\n",
        "        history = np.zeros((epochs,2))\n",
        "        for _ in range(epochs):\n",
        "            Gradient_P = np.zeros((len(list_user),factor))\n",
        "            Gradient_Q = np.zeros((len(list_movie),factor))\n",
        "            for i in range(len(Train_user)):\n",
        "                user = Train_user[i]\n",
        "                movie = Train_movie[i]\n",
        "                error = Train_rate[i]-np.dot(Q[movie],P[user])\n",
        "                Gradient_P[user] += error * Q[movie] \n",
        "                Gradient_Q[movie] += error * P[user]\n",
        "            for i in range(len(list_user)):\n",
        "                Gradient_P[i] -= Lambda_P * P[i]\n",
        "            for i in range(len(list_movie)):\n",
        "                Gradient_Q[i] -= Lambda_Q * Q[i]\n",
        "            P = P + lr*Gradient_P\n",
        "            Q = Q + lr*Gradient_Q\n",
        "            # calculate training and testing rmse after each epoch\n",
        "            #history[_,0] = sum([(Train_rate[i]-np.dot(Q[Train_movie[i]],P[Train_user[i]]))**2 for i in range(len(Train_user))])/len(Train_user)\n",
        "            #history[_,1] = sum([(Validation_rate[i]-np.dot(Q[Validation_movie[i]],P[Validation_user[i]]))**2 for i in range(len(Validation_user))])/len(Validation_user)\n",
        "            \n",
        "        best_rmse.append((sum([(Validation_rate[i]-np.dot(Q[Validation_movie[i]],P[Validation_user[i]]))**2 for i in range(len(Validation_user))])/len(Validation_user))**.5)\n",
        "    return sum(best_rmse)/K,factor,Lambda_P,Lambda_Q,epochs,lr\n",
        "\n",
        "#GD_CV([5,0.1,0.2,20,0.001])\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    P = [[3,5,7,10],[0.1,0.2],[0.1,0.2],[300],[0.001]] # Factor, lambda_P, lambda_Q, epochs(should be 300, 20 is for testing only),learning rate \n",
        "    pairs = product(*P)\n",
        "    pool = multiprocessing.Pool() # change the process amount based on your own CPU, default is using all Threads\n",
        "    result = pool.map(GD_CV, pairs)\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "    print(result)\n",
        "    with open('A2.txt', 'w') as file:\n",
        "        for i in result:\n",
        "            file.writelines([str(t)+',' for t in i]+[\"\\n\"])\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FhzMyRE2ZQl",
        "colab_type": "text"
      },
      "source": [
        "## Step 3:   Postprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkBRojjx2ZQl",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Introduction about Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-uQo8tW2ZQm",
        "colab_type": "text"
      },
      "source": [
        "After matrix factorization, postprocessing will be performed to improve accuracy. Here we apply kernel ridge regression (P3) to previous SVD results. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG-zf4Cw2ZQn",
        "colab_type": "text"
      },
      "source": [
        "Commonly we will predict rating by $r_{ui}=q_{i}^\\intercal {p_{u}}$. For P3, it discards all latent user feature vectors $P$ after training matrix factorization algorithms and try to predict rating for each user $u$ by fitting kernel ridge regression and using latent movie feature vector $Q$ as predictors. By changing Gram matrix, we can have different kernels. The Gaussian kernel in Paper 2 does not perform that well as we expect, so we change to ***rbf*** kernel and tune its parameter. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLfgeDUe2ZQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## for A1 & A2, we will tune parameters separately\n",
        "\n",
        "def KRR(Q,alpha=0.5,gamma=0.01):\n",
        "    train_error = []\n",
        "    test_error = []\n",
        "    \n",
        "    for i in Test.userId.unique():\n",
        "        ## training set for user i\n",
        "        y = []\n",
        "        X = []\n",
        "        \n",
        "        ## testing set for user i\n",
        "        X_test = []\n",
        "        y_test = []\n",
        "        \n",
        "        ## remember we should normalize movie vectors  \n",
        "        for j in range(len(Test)):\n",
        "            if Test_user[j]==i:\n",
        "                X_test.append(Q[Test_movie[j]]/np.linalg.norm(Q[Test_movie[j]]))\n",
        "                y_test.append(Test_rate[j])\n",
        "        for j in range(len(Train)):\n",
        "            if Train_user[j]==i:\n",
        "                X.append(Q[Train_movie[j]]/np.linalg.norm(Q[Train_movie[j]]))\n",
        "                y.append(Train_rate[j])\n",
        "        \n",
        "        clf = KernelRidge(alpha = alpha, kernel = \"rbf\", gamma = gamma)\n",
        "        clf.fit(X,y)\n",
        "        y_estimate = clf.predict(X_test)\n",
        "        y_train_estimate = clf.predict(X)\n",
        "        train_error = train_error + [y[k] - y_train_estimate[k] for k in range(len(y))]\n",
        "        test_error = test_error + [y_test[k] - y_estimate[k] for k in range(len(y_test))]\n",
        "        \n",
        "    print((sum([train_error[i]**2 for i in range(len(train_error))])/len(train_error))**.5)\n",
        "    print((sum([test_error[i]**2 for i in range(len(test_error))])/len(test_error))**.5)\n",
        "    return (sum([test_error[i]**2 for i in range(len(test_error))])/len(test_error))**.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckpF-T162ZQp",
        "colab_type": "code",
        "outputId": "8271dbd8-a498-4af7-b887-f52a76eee28d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# show RMSE for A1P3 and calculate running time\n",
        "\n",
        "start_13 = timeit.default_timer()\n",
        "A1P3 = KRR(result1[1],alpha=0.5,gamma=0.1)\n",
        "stop_13 = timeit.default_timer()\n",
        "\n",
        "print('Running Time for A1P3: ', stop_13 - start_13, 's')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6406904196028844\n",
            "0.8982856059265927\n",
            "Running Time for A1P3:  43.12218872399899 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idwDOGJS2ZQt",
        "colab_type": "code",
        "outputId": "3d2a3b1d-9a51-4f2e-b83a-bfe55e34c06c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# show RMSE for A2P3 and calculate running time\n",
        "\n",
        "start_23 = timeit.default_timer()\n",
        "A2P3 = KRR(result2[1],alpha=0.5,gamma=0.2)\n",
        "stop_23 = timeit.default_timer()\n",
        "\n",
        "print('Running Time for A2P3: ', stop_23 - start_23, 's')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9284085638595198\n",
            "0.9379110179456425\n",
            "Running Time for A2P3:  42.527320585999405 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWYfIasC2ZQx",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Parameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwhfjAxxzJ42",
        "colab_type": "text"
      },
      "source": [
        "In this step, we tune these two parameters for A1P3 and A2P3 by inputing different values combination rather than serious cross validation. Because cross validation will split datasets and thus require different optimal $Q$ vectors. To make it easier, we just leverage the optimal $Q$ vectors from step 1 and 2 and then try different parameters for P3 without cross validation. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiwQy40z2ZQ2",
        "colab_type": "text"
      },
      "source": [
        "## Step 4:   Evaluation and Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNeLFIyJ2ZQ3",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 RMSE and Running Time Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMZM_YU12ZQ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "0e409336-fbcc-40b6-f3ed-78c73110459d"
      },
      "source": [
        "data = [[result1[2][199][0],result1[2][199][1],stop1-start1,A1P3,stop_13-start_13],[result2[2][499][0],result2[2][499][1],stop2-start2,A2P3,stop_23-start_23]]\n",
        "algo_list=['A1','A2']\n",
        "col_list = ['train RMSE','test RMSE','SVD time','P3 test RMSE','P3 time']\n",
        "pd.DataFrame(data, algo_list, col_list)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train RMSE</th>\n",
              "      <th>test RMSE</th>\n",
              "      <th>SVD time</th>\n",
              "      <th>P3 test RMSE</th>\n",
              "      <th>P3 time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>A1</th>\n",
              "      <td>0.517245</td>\n",
              "      <td>0.856704</td>\n",
              "      <td>280.859396</td>\n",
              "      <td>0.898286</td>\n",
              "      <td>43.122189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A2</th>\n",
              "      <td>0.820165</td>\n",
              "      <td>0.859496</td>\n",
              "      <td>522.432323</td>\n",
              "      <td>0.937911</td>\n",
              "      <td>42.527321</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    train RMSE  test RMSE    SVD time  P3 test RMSE    P3 time\n",
              "A1    0.517245   0.856704  280.859396      0.898286  43.122189\n",
              "A2    0.820165   0.859496  522.432323      0.937911  42.527321"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgjA0Nmj2ZQ6",
        "colab_type": "text"
      },
      "source": [
        "Conclusion: A1 has lower test error and takes shorter time to process factorization than A2. A1 is more time-saving because A1 converges quickly and we set epoch value for A1 to be 200 while epoch for A2 is 500. In addition, P3 postprocessing seems to lose its power regarding improving accuracy on both algorithms. We think this may be reasonable because kernel ridge regression only utilize information in movie feature vectors and thus in some cases may not be a wise choice to improve performance of our recommender system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhbBB9jH2ZQ6",
        "colab_type": "text"
      },
      "source": [
        "### 4.2 Converging Performance Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp2FYR_Z8ZoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result1 = A1(epochs=500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOrwmk6L2ZQ7",
        "colab_type": "code",
        "outputId": "e378faf4-e55a-4e19-db36-cc95605037e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "x = range(0,500)\n",
        "plt.title('RMSE converging performance for A1 vs A2')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('RMSE')\n",
        "plt.plot(x, result1[2])\n",
        "plt.plot(x, result2[2])\n",
        "plt.legend(['A1 training','A1 testing','A2 training', 'A2 testing'], loc='upper right')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd127beb6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXApBRETDpRBERDTcNdRo8jC4iY6fAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-PBGGsvjKri",
        "colab_type": "text"
      },
      "source": [
        "From above plot, we can tell that A1 converges faster than A2. In order to compare A1 and A2 in the same plot, we set epoch value of A1 to be 500 here. In addition, A1 has much lower training error than A2 and seems to have some overfitting problem. This is also reasonable because A1 has larger dimension of feature factors and somehow complex if the epoch value is the same as A2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O49yEJRP2ZQ8",
        "colab_type": "text"
      },
      "source": [
        "### 4.3 Future Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOvtkUu_OkAI",
        "colab_type": "text"
      },
      "source": [
        "How to set initial values for P and Q is an interesting subject. In the beginning stage of our project, we set values of P and Q equal to random number from Normal(0,0.1). This may cause many problems and result in larger RMSE because it assumes the expectation of $q_{i}^Tp_{u}$ is 0 before updating.\n",
        "\n",
        "Therefore, to fix this issue, we set intial values that can somehow let the expectation of $q_{i}^Tp_{u}$ to be the mean of ratings in our training set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiQZSMQhi2p-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mu = (sum(Train_rate)/Factor/len(Train_rate))**.5) \n",
        "#P = np.random.normal(mu, .05, (len(list_user),Factor)) \n",
        "#Q = np.random.normal(mu, .05, (len(list_user),Factor)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxhUpo-Si57c",
        "colab_type": "text"
      },
      "source": [
        "This provides more prior information than random guesses and proves to improve the accuracy of our algorithms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ5efr9N2ZQ-",
        "colab_type": "text"
      },
      "source": [
        "## Reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pmgriR-2ZQ_",
        "colab_type": "text"
      },
      "source": [
        "P1: Yehuda Koren, Robert Bell, Chris Volinsky. Matrix Factorization Techniques For Recommender Systems. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9pWiKVj2ZRA",
        "colab_type": "text"
      },
      "source": [
        "P3: Ruslan Salakhutdinov, Andriy Mnih. Probabilistic Matrix Factorization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wQcQvGY2ZRA",
        "colab_type": "text"
      },
      "source": [
        "P2: Arkadiusz Paterek. Improving Regularized Singular Value Decomposition for Collaborative Filtering. "
      ]
    }
  ]
}